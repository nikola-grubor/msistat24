---
title: "A short introduction to probability"
date: last-modified
author: "Dr Nikola Grubor"
# institute: "Institut za Medicinsku Statistiku i Informatiku"
logo: "slike/logo.png"

# format:
#   revealjs:
#     slide-number: true
#     show-slide-number: speaker
#     theme: [default, custom.scss]
# 
# revealjs-plugins:
#   - revealjs-text-resizer
---
```{r}
library(glue)
library(here)
library(tidyverse)
library(tinytable)
library(gtsummary)
source(file = here("slides", "theme", "ggthemes.R"))
```

## de Méré's problem

:::: columns

::: {.column}
![Pierre de Fermat](slike/fermat.jpg){width=90%}
:::

::: {.column}
![Blaise Pascal](slike/pascal.jpg){width=90%}
:::

::::

## The need for probability theory

:::: columns

::: {.column}
Probability as an extension of Aristotle's logic.

We get to talk about the (un)certainty of belief.
:::

::: {.column}
![](slike/jaynes.jpg){width=70%}
:::

::::

## Basic terms in probability theory {.smaller}

[Experiment]{.yellow}
  : An activity that produces an outcome (choosing a new path to test if it is faster than the old one).

$$ \text{Experiment} \rightarrow \text{Outcome} $$

[Sample space]{.yellow}
  : The set of all possible outcomes of an experiment.

$$ \text{Dice sample space:} \; \omega = \{1,2,3,4,5,6\} $$

[Event]{.yellow}
  : A subset of the outcome space.

$$ \text{Dice roll event} \; x = 6 $$

## Types of events

An event is a set of possible outcomes, and can be:

- Deterministic (e.g. Vitamin C deficiency $\rightarrow$ Scurvy)

- Random (stochastic)

The [sample space]{.yellow} of (elementary) [outcomes]{.yellow} $\omega$ is a set of all possible outcomes.

$$ \omega = \{A, B\, O, AB\} \; \; \; \omega = \{\text{healthy}, \text{sick}\} $$

## Somatic or germline mutations

![](slike/events.png)

## Definition of probability {.center}

::: {.r-fit-text}
Probability is a [measure of expectation]{.yellow} 

of some random event.
:::

::: {.notes}
A random event = the result of a process that we don't know how it works. Measure, process by which
I add a number to something (meter and distance, knowledge and grades).
:::

## Expectation is more general than the mean

:::: columns

::: {.column}

![](slike/catan.png){fig-align="center"}
:::

::: {.column}

::: {.callout-note}
Expectations are everywhere in medicine: survival, time to recovery after taking the drug,
lab. tests (markers, biochemical parameters, eGFR), etc.
:::

:::

::::

::: {.notes}
The expected value does not have to be the most common (mode), nor does it does have to coincide with everyday use.
It doesn't even have to be a value that can happen to be 3.5 on a 6-sided die.
:::

## Law of large numbers

```{r}

set.seed(123)

throws <- 100
experiment <- sample(1:6, size = throws, replace = TRUE)
runningavg <- cumsum(experiment) / 1:length(experiment)

tibble(x = 1:length(runningavg), y = runningavg) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(color = "#F7F8F9") +
  geom_hline(
    yintercept = 3.5,
    colour = "#F4BA02",
    linewidth = 1,
    linetype = "dashed"
  ) +
  ggdist::theme_ggdist(base_size = 18) +
  theme_blue() +
  ylim(1, 6) +
  labs(y = "Mean (expectation)", x = "Event")
```


## How do we determine probability?

1. Objective
   - Theoretical (mathematical)
   - Empirical (statistical)

2. Subjective
   - Belief

## Theoretical probability

- Available before measurement
- All possible outcomes are equally likely

![](slike/classical.png){fig-align="center"}

## Empirical probability

Empirical probability is determined (by counting) after observing the event.

:::: columns

::: {.column}
$$ p = \frac{\text{expected}}{\text{total}} $$ 
:::

::: {.column}

```{r}
tribble(
  ~"Blood group", ~"Relative frequency",
  "O", "45%",
  "A", "39%",
  "B", "12%",
  "AB", "4%"
) %>% tt(.) %>% style_tt(fontsize = 1)
```

:::

::::

## Subjective probability

:::: columns

::: {.column}
- Belief
- Expert opinion

```{r}
#| fig-width: 6
#| fig-height: 5

ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
  stat_function(
    fun = dnorm,
    args = list(0.2, 0.1),
    color = "#F7F8F9",
    linewidth = 1
  ) +
  stat_function(
    fun = dnorm,
    args = list(0.8, 0.07),
    color = "#F7F8F9",
    linewidth = 1
  ) +
  geom_area(
    stat = "function",
    fun = dnorm,
    args = list(0.2, 0.1),
    fill = "grey",
    alpha = 0.7
  ) +
  geom_area(
    stat = "function",
    fun = dnorm,
    args = list(0.8, 0.07),
    fill = "#F4BA02",
    alpha = 0.7
  ) +
  geom_segment(
    x = 0.4,
    y = 1.5,
    xend = 0.65,
    yend = 1.5,
    size = 2,
    color = "#F7F8F9",
    lineend = "round",
    linejoin = "mitre",
    arrow = arrow(length = unit(0.4, "cm"))
  ) +
  annotate(
    "text",
    x = 0.525,
    y = 1.8,
    label = "evidence",
    color = "#F7F8F9"
  ) +
  annotate(
    "text",
    x = 0.2,
    y = 1.8,
    label = "prior",
    fontface = "bold.italic",
    color = "#F7F8F9"
  ) +
  annotate(
    "text",
    x = 0.8,
    y = 1.8,
    label = "posterior",
    fontface = "bold.italic",
    color = "#F7F8F9"
  ) +
  coord_cartesian(ylim = c(0.01, 8), expand = FALSE) +
  theme_blue_void() +
  xlim(-0.15, 1.1)
```


:::

::: {.column}

```{mermaid}

flowchart TD
  S(Symptom) --> A("Prior Belief")
  Z(Sign) --> A
  P(Prevalence) --> A
  A --> T{"Diagnostic test"}
  T --> AP("Posterior Belief")

```

:::

::::

## Properties of probability

Axioms:

- Non-negativity [0, 1]
- Normality (sum = 1)
- Additivity

Additional dates:

- Event probability ($p$)
- Probability of the opposite event ($1-p = q$)
- Complementarity ($p+q = 1$)

## Exclusivity

Events are exclusive if they cannot occur simultaneously.

- Blood group
- Flu symptoms
- Medical sign
- Diagnoses

## Laws of probability: addition (1)

Addition (summation of probabilities) of [exclusive]{.yellow} events.

::: r-stack

![](slike/prob1.png){fig-align="center"}

![](slike/prob2.png){fig-align="center" .fragment}
:::

## Laws of Probability: Addition (2)

Addition (summation of probabilities) of [non-exclusive]{.blue} events.

::: r-stack

![](slike/prob3.png){fig-align="center"}

![](slike/prob4.png){fig-align="center" .fragment}

![](slike/prob5.png){fig-align="center" .fragment}

:::

## Laws of probability: multiplication

Multiplication of [exclusive]{.blue} events.

![](slike/prob7.png){fig-align="center"}

$$ P(A \cap B) = P(A) \times P(B) $$

## Conditional probability

![](slike/prob7.png){fig-align="center"}

$$ P(A \cap B) = P(A) \times P(B|A) = P(B) \times P(A|B) $$

## Probability in diagnostics

![](slike/scenario.png){fig-align="center"}

## CENTOR Score

:::: columns

::: {.column width="40%"}

- The contribution of each symptom/sign to the likelihood of strep. infections
- The result is a pre-test probability

:::

::: {.column width="60%"}

![](slike/centor.png){fig-align="center"}
:::

::::

## Theoretical probability distributions

Theoretical probability distributions are specific mathematical descriptions ([models]{.yellow}) of random phenomena.

- Binomial
- Normal

## Mathematical model

:::: columns

::: {.column}
![Mathematical model](slike/plane1.jpg)
:::

::: {.column}
![Reality](slike/plane2.jpg)
:::

::::

## Bernoulli's experiment

:::: columns

::: {.column}

- A model of the coin tossing process.
- Basic building unit for other distributions.

A coin tossed once:

```{r}
#| echo: true
rbinom(n = 1, size = 1, prob = 0.5)
```

Coin tossed 10 times:

```{r}
#| echo: true
rbinom(10, 1, 0.5)
```


:::

::: {.column}
![](slike/bern.png)
:::

::::

## Binomial distribution

:::: columns

::: {.column}

Conditions:

- Exclusive events
- Constant probability
- Independent

:::

::: {.column}

The binomial probability is given by:

$$ P(X = x) = \frac{n!}{x!(n-x)!}p^{x}q^{n-x} $$

:::

::::

```{r}
#| fig-width: 10
#| fig-height: 3
#| fig-align: "center"

data.frame(heads = 0:10, prob = dbinom(x = 0:10, size = 10, prob = 0.5)) %>%
  mutate(Heads = ifelse(heads == 2, "2", "other")) %>%
ggplot(aes(x = factor(heads), y = prob, fill = Heads)) +
  geom_col() +
  geom_text(
    aes(label = round(prob,2), y = prob + 0.01),
    position = position_dodge(0.9),
    color = "#F7F8F9",
    size = 3,
    vjust = 0
  ) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  scale_fill_manual(values = c("2" = "tomato", "other" = "#F4BA02")) +
  labs(x = "Successes in 10 coin tosses (x)",
       y = "Probability",
       fill = "N successes") 
```


## Exercise 1

::: {.r-fit-text}

The frequency of hypertension in the population over 65 years old is [42%]{.yellow}. 

What is the probability that [two]{.yellow} people with hypertension will be in a 

random sample of [7]{.yellow} people chosen from that same population?

:::

## Why is the normal distribution frequent?

:::: columns

::: {.column}

- The normal distribution is created by adding (or multiplying) the results of many smaller processes.
- Measurement errors, growth variations, and molecular velocity are examples of such processes.

:::

::: {.column}

![](slike/galton.gif)

:::

::::

::: {.notes}
Poređaj 1000 svojih najbližih prijatelja na sredinu fudbalskog terena. Svako ima
novčić u ruci. Kad padne glava ide se korak napred, a kad padne pismo korak
nazad. Nakon 16 bacanja izmeri udaljenost od pocetne linije. Da li možes da 
znas proporciju ljudi koja stoji na liniji? A 5 metara od linije? I ako ne znamo
gde će pojedinačna osoba završiti, možemo znati koje će udaljenosti biti
najčešće.
:::

## Normal distribution

```{r}
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  annotate("segment", x = 0, y = 0, yend = 0.4,
           color = "#F4BA02", linewidth = 1, linetype = 2,) +
  annotate("segment", x = 0.02, y = 0.2, xend = 1.1,
           color = "#F4BA02", linewidth = 1, linetype = 1,
           arrow = arrow(length=unit(0.30,"cm"), ends="both", type = "open")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1),
                color = "#F4BA02", linewidth = 2) + 
  annotate("text", x = 0.55, y = 0.225, label = c("sd"), color = "#F7F8F9",
           size = 6) +
  annotate("text", x = 0, y = 0.45, label = c("mean"), color = "#F7F8F9",
           size = 6) +
  annotate("text", x = 1.8, y = 0.225, label = c("point of\ninflection"), color = "#F7F8F9",
           size = 6) +
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue()
```

## Standard normal distribution

Normal distribution where $\bar x = 0$ and $sd = 1$. It is given by the formula: 

$$ z_i = \frac{x_i - \mu}{\sigma} $$

It used to be important when calculation was done by hand via probability tables.

::: {.notes}
Inace bi morali da napravimo beskonacno tablica verovatnoca;
za svaku mogucu normalnu distribuciju.
:::

## Probability table

![](slike/table.png){fig-align="center"}

::: {.notes}
30 "zakljucanih" ljudskih kalkulatora koji racunaju verovatnocu.
:::

## Student's t-distribution

```{r}
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1),
                color = "#F4BA02", linewidth = 2) + 
  stat_function(fun = dt, n = 101, args = list(df = 1),
                color = "tomato", linewidth = 2) + 
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue()
```

::: {.notes}
100 god stara.Varijabilitet populacije nespoznat, pa cemo uzeti iz uzorka, sto dodaje jos
nesigurnosti. Za svaki stepen slobode (koliko informacija smo iskoristili da procenimo variabilitet) postoji posebna t-distribucija. t-dist se priblizava z-dist za beskonacno stepena slobode.
:::

## Chi-square distribution

```{r}
ggplot(data = data.frame(x = c(0, 10)), aes(x)) +
  stat_function(fun = dchisq, n = 101, args = list(df = 3),
                color = "#F4BA02", linewidth = 2) + 
  stat_function(fun = dchisq, n = 101, args = list(df = 4),
                color = "#F4DA02", linewidth = 2) + 
  stat_function(fun = dchisq, n = 101, args = list(df = 5),
                color = "#F4FA02", linewidth = 2) + 
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue()
```

::: {.notes}
Uzorci iz Z-dist^2^ (postaju pozitivni) i to postane hi-kvadrat.
(sum of square deviations) / (pop. variance) -> kako idu df inf hi postaje z.
F dist. (dist of ratio of two variances)
:::

## 68-95-99.7%

```{r}
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  annotate("segment", x = 1, y = 0, yend = 0.3,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = -1, y = 0, yend = 0.3,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = 2, y = 0, yend = 0.4,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = -2, y = 0, yend = 0.4,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = 3, y = 0, yend = 0.5,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = -3, y = 0, yend = 0.5,
           color = "#F4BA02", linewidth = 1, linetype = 2) +
  annotate("segment", x = -1, y = 0.5, xend = 1,
           color = "#F4BA02", linewidth = 1, linetype = 1,
           arrow = arrow(length=unit(0.30,"cm"), ends="both", type = "open")) +
  annotate("segment", x = -2, y = 0.6, xend = 2,
           color = "#F4BA02", linewidth = 1, linetype = 1,
           arrow = arrow(length=unit(0.30,"cm"), ends="both", type = "open")) +
  annotate("segment", x = -3, y = 0.7, xend = 3,
           color = "#F4BA02", linewidth = 1, linetype = 1,
           arrow = arrow(length=unit(0.30,"cm"), ends="both", type = "open")) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1),
                color = "#F4BA02", linewidth = 2) + 
  annotate("text", x = 0, y = 0.55, label = c("68%"), color = "#F7F8F9",
           size = 6) +
  annotate("text", x = 0, y = 0.65, label = c("95%"), color = "#F7F8F9",
           size = 6) +
  annotate("text", x = 0, y = 0.75, label = c("99.7%"), color = "#F7F8F9",
           size = 6) +
  ylab("") +
  scale_y_continuous(breaks = NULL) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  scale_x_continuous(breaks = scales::pretty_breaks(),
                     labels = scales::label_percent(suffix = " sd", scale = 1))
```

## Exercise 2

::: {.r-fit-text}

In a population of women between the ages of 25 and 50, serum uric acid values

are normally distributed with a [mean 333]{.yellow} mmol/L and a

[standard deviation 30]{.yellow} mmol/L.

:::

::: {.r-fit-text}

What is the probability that a randomly selected person from this population has a 

serum uric acid value [greater than 410]{.yellow} mmol/l?

:::

## Probability calculation: normal distribution

:::: {.r-stack}

```{r}
set.seed(123)

N <- 1000
mkis <- tibble(
  id = 1:N,
  TA = rnorm(N, mean = 333, sd = 30)
)

mkis %>% 
  ggplot(aes(x = TA)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#F4BA02", size = 1) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  labs(y = "Probability",
       x = "Uric acid [mmol/L]")
```

::: {.fragment}

```{r}

mkis %>% 
  ggplot(aes(x = TA)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#F4BA02", size = 1) +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30), color = "#F7F8F9", size = 1.5) +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  labs(y = "Probability",
       x = "Uric acid [mmol/L]")
```

:::

::: {.fragment}

```{r}

mkis %>% 
  ggplot(aes(x = TA)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#F4BA02", size = 1) +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30),
                xlim = c(333-30,333+30),
                geom = "area", alpha = 3/4, fill = "dodgerblue") +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30),
                xlim = c(333+2*30, 333+3*30),
                geom = "area", alpha = 3/4, fill = "tomato") +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30), color = "#F7F8F9", size = 1.5) +
  annotate("text", label = "More probable", x = 270, y = 0.010, size = 7, color = "dodgerblue") +
  annotate("text", label = "Less\nprobable", x = 410, y = 0.005, size = 7, color = "tomato") +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  labs(y = "Probability",
       x = "Uric acid [mmol/L]")
```

:::

::: {.fragment}

```{r}

mkis %>% 
  ggplot(aes(x = TA)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "#F4BA02", size = 1) +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30),
                xlim = c(410, 333+3*30),
                geom = "area", alpha = 3/4, fill = "tomato") +
  stat_function(fun = dnorm, args = list(mean = 333, sd = 30), 
                color = "#F7F8F9", size = 1.5) +
  annotate("text", label = "Over 410 mmol/L", x = 420, y = 0.0025, 
           size = 7, color = "tomato") +
  ggdist::theme_ggdist(base_size=15) +
  theme_blue() +
  labs(y = "Probability",
       x = "Uric acid [mmol/L]")
```

:::

::::